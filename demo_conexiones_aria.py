"""
ğŸ”— ARIA - DEMOSTRACIÃ“N EN VIVO DE CONEXIONES
==========================================

Este script hace una demostraciÃ³n real de cÃ³mo ARIA se conecta a fuentes externas
"""

import requests
import feedparser
import json
from urllib.parse import quote
from datetime import datetime

def demo_wikipedia_connection():
    """Demuestra conexiÃ³n real a Wikipedia"""
    print("=" * 60)
    print("ğŸŒ DEMOSTRACIÃ“N EN VIVO: CONEXIÃ“N A WIKIPEDIA")
    print("=" * 60)
    
    topic = "artificial intelligence"
    print(f"ğŸ¯ Buscando informaciÃ³n sobre: '{topic}'")
    
    # Construir URL como lo hace ARIA
    search_url = f"https://en.wikipedia.org/api/rest_v1/page/summary/{quote(topic)}"
    print(f"ğŸ”— URL construida: {search_url}")
    
    try:
        print("\nğŸ“¡ Enviando peticiÃ³n HTTP...")
        response = requests.get(search_url, timeout=10)
        
        print(f"ğŸ“Š CÃ³digo de respuesta: {response.status_code}")
        print(f"ğŸ“ TamaÃ±o de respuesta: {len(response.content)} bytes")
        
        if response.status_code == 200:
            data = response.json()
            
            print("\nâœ… DATOS EXTRAÃDOS:")
            print(f"   ğŸ“° TÃ­tulo: {data.get('title', 'N/A')}")
            print(f"   ğŸ“„ Extracto: {data.get('extract', 'N/A')[:150]}...")
            print(f"   ğŸ”— URL: {data.get('content_urls', {}).get('desktop', {}).get('page', 'N/A')}")
            
            # Simular guardado como lo hace ARIA
            knowledge_item = {
                'topic': topic,
                'title': data.get('title', topic),
                'content': data.get('extract', ''),
                'source_type': 'wikipedia',
                'source_url': data.get('content_urls', {}).get('desktop', {}).get('page', ''),
                'confidence_score': 0.9,
                'timestamp': datetime.now().isoformat()
            }
            
            print("\nğŸ’¾ ESTRUCTURA DE DATOS COMO ARIA LA GUARDA:")
            print(json.dumps(knowledge_item, indent=2, ensure_ascii=False))
            
            return True
        else:
            print(f"âŒ Error HTTP: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ Error de conexiÃ³n: {e}")
        return False

def demo_rss_connection():
    """Demuestra conexiÃ³n real a RSS feeds"""
    print("\n" + "=" * 60)
    print("ğŸ“° DEMOSTRACIÃ“N EN VIVO: CONEXIÃ“N A RSS FEEDS")
    print("=" * 60)
    
    feed_url = "https://feeds.feedburner.com/TechCrunch"
    print(f"ğŸ“¡ Conectando a: {feed_url}")
    
    try:
        print("\nğŸ“¡ Parseando RSS feed...")
        feed = feedparser.parse(feed_url)
        
        print(f"ğŸ“Š TÃ­tulo del feed: {feed.feed.get('title', 'N/A')}")
        print(f"ğŸ“ˆ ArtÃ­culos encontrados: {len(feed.entries)}")
        
        if feed.entries:
            print("\nğŸ“° ÃšLTIMOS 3 ARTÃCULOS:")
            
            for i, entry in enumerate(feed.entries[:3]):
                print(f"\n   {i+1}. ğŸ“° {entry.get('title', 'Sin tÃ­tulo')}")
                print(f"      ğŸ“… Fecha: {entry.get('published', 'N/A')}")
                print(f"      ğŸ”— URL: {entry.get('link', 'N/A')}")
                print(f"      ğŸ“„ Resumen: {entry.get('summary', 'N/A')[:100]}...")
            
            # Simular selecciÃ³n por relevancia como ARIA
            topic = "artificial intelligence"
            print(f"\nğŸ¯ Buscando artÃ­culos relevantes a '{topic}':")
            
            relevant_articles = []
            topic_words = topic.lower().split()
            
            for entry in feed.entries[:10]:
                title = entry.get('title', '').lower()
                summary = entry.get('summary', '').lower()
                
                relevance = 0
                for word in topic_words:
                    if word in title:
                        relevance += 2
                    if word in summary:
                        relevance += 1
                
                if relevance > 0:
                    relevant_articles.append((entry, relevance))
            
            if relevant_articles:
                # Ordenar por relevancia
                relevant_articles.sort(key=lambda x: x[1], reverse=True)
                best_article, relevance_score = relevant_articles[0]
                
                print(f"\nâœ… ARTÃCULO MÃS RELEVANTE (puntuaciÃ³n: {relevance_score}):")
                print(f"   ğŸ“° {best_article.get('title', 'N/A')}")
                print(f"   ğŸ”— {best_article.get('link', 'N/A')}")
                
                # Como ARIA lo guardarÃ­a
                knowledge_item = {
                    'topic': topic,
                    'title': best_article.get('title', ''),
                    'content': best_article.get('summary', '')[:500],
                    'source_type': 'rss_news',
                    'source_url': best_article.get('link', ''),
                    'relevance_score': min(relevance_score / 5.0, 1.0),
                    'confidence_score': 0.7,
                    'timestamp': datetime.now().isoformat()
                }
                
                print("\nğŸ’¾ COMO ARIA LO GUARDARÃA:")
                print(json.dumps(knowledge_item, indent=2, ensure_ascii=False))
                
                return True
            else:
                print(f"âš ï¸ No se encontraron artÃ­culos relevantes a '{topic}'")
                return False
        else:
            print("âŒ No se encontraron artÃ­culos en el feed")
            return False
            
    except Exception as e:
        print(f"âŒ Error parseando RSS: {e}")
        return False

def demo_arxiv_connection():
    """Demuestra conexiÃ³n real a ArXiv"""
    print("\n" + "=" * 60)
    print("ğŸ”¬ DEMOSTRACIÃ“N EN VIVO: CONEXIÃ“N A ARXIV")
    print("=" * 60)
    
    topic = "machine learning"
    query = f"all:{quote(topic)}"
    url = f"http://export.arxiv.org/api/query?search_query={query}&start=0&max_results=3"
    
    print(f"ğŸ¯ Buscando papers sobre: '{topic}'")
    print(f"ğŸ”— URL: {url}")
    
    try:
        print("\nğŸ“¡ Consultando ArXiv...")
        response = requests.get(url, timeout=15)
        
        print(f"ğŸ“Š CÃ³digo de respuesta: {response.status_code}")
        
        if response.status_code == 200:
            print("âœ… Respuesta recibida, parseando XML...")
            
            # ArXiv devuelve XML, simular el parsing
            import xml.etree.ElementTree as ET
            root = ET.fromstring(response.content)
            
            # Namespace para ArXiv
            ns = {'atom': 'http://www.w3.org/2005/Atom'}
            entries = root.findall('atom:entry', ns)
            
            print(f"ğŸ“š Papers encontrados: {len(entries)}")
            
            if entries:
                print("\nğŸ“– PRIMEROS 3 PAPERS:")
                
                for i, entry in enumerate(entries[:3]):
                    title = entry.find('atom:title', ns)
                    summary = entry.find('atom:summary', ns)
                    link = entry.find('atom:id', ns)
                    published = entry.find('atom:published', ns)
                    
                    if title is not None:
                        print(f"\n   {i+1}. ğŸ“– {title.text.strip()}")
                        if published is not None:
                            print(f"      ğŸ“… Publicado: {published.text}")
                        if link is not None:
                            print(f"      ğŸ”— URL: {link.text}")
                        if summary is not None:
                            print(f"      ğŸ“„ Resumen: {summary.text.strip()[:150]}...")
                
                # Simular como ARIA guardarÃ­a el primer paper
                first_entry = entries[0]
                title = first_entry.find('atom:title', ns)
                summary = first_entry.find('atom:summary', ns)
                link = first_entry.find('atom:id', ns)
                
                if title is not None and summary is not None:
                    knowledge_item = {
                        'topic': topic,
                        'title': title.text.strip(),
                        'content': summary.text.strip()[:1000],
                        'source_type': 'arxiv',
                        'source_url': link.text if link is not None else '',
                        'confidence_score': 0.95,
                        'relevance_score': 0.9,
                        'category': 'scientific_paper',
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    print("\nğŸ’¾ COMO ARIA GUARDARÃA EL PRIMER PAPER:")
                    print(json.dumps(knowledge_item, indent=2, ensure_ascii=False))
                    
                    return True
            else:
                print("âŒ No se encontraron papers")
                return False
        else:
            print(f"âŒ Error HTTP: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ Error consultando ArXiv: {e}")
        return False

def mostrar_flujo_completo():
    """Muestra el flujo completo de aprendizaje"""
    print("\n" + "=" * 60)
    print("ğŸ”„ FLUJO COMPLETO DE APRENDIZAJE DE ARIA")
    print("=" * 60)
    
    print("\n1ï¸âƒ£ INICIO DEL CICLO")
    print("   ğŸ² ARIA selecciona tema aleatorio: 'quantum computing'")
    print("   ğŸ¯ Elige fuente aleatoria: Wikipedia")
    
    print("\n2ï¸âƒ£ CONSTRUCCIÃ“N DE PETICIÃ“N")
    print("   ğŸ”¤ Codifica tema: quantum%20computing")
    print("   ğŸ”— URL: https://en.wikipedia.org/api/rest_v1/page/summary/quantum%20computing")
    
    print("\n3ï¸âƒ£ PETICIÃ“N HTTP")
    print("   ğŸ“¡ requests.get(url, timeout=10)")
    print("   â±ï¸ Espera mÃ¡ximo 10 segundos")
    
    print("\n4ï¸âƒ£ PROCESAMIENTO")
    print("   ğŸ“„ Parsea JSON de respuesta")
    print("   ğŸ” Extrae palabras clave")
    print("   ğŸ“Š Calcula puntuaciÃ³n de confianza")
    
    print("\n5ï¸âƒ£ ALMACENAMIENTO")
    print("   ğŸ’¾ Guarda en SQLite: data/aria_advanced_learning.db")
    print("   ğŸ·ï¸ Etiqueta con metadatos")
    
    print("\n6ï¸âƒ£ ESTADÃSTICAS")
    print("   ğŸ“ˆ Incrementa contadores")
    print("   ğŸ“Š Actualiza mÃ©tricas de Ã©xito")
    
    print("\n7ï¸âƒ£ PAUSA Y REPETICIÃ“N")
    print("   â±ï¸ Espera 30-120 segundos")
    print("   ğŸ” Vuelve al paso 1 con nuevo tema")
    
    print("\nâœ¨ RESULTADO: Conocimiento real y actualizado almacenado!")

def main():
    """FunciÃ³n principal de demostraciÃ³n"""
    print("ğŸš€ ARIA - DEMOSTRACIÃ“N EN VIVO DE CONEXIONES A FUENTES EXTERNAS")
    print("=" * 80)
    print("ğŸ“… Fecha de demostraciÃ³n:", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    print("\nâš ï¸ IMPORTANTE: Esta demostraciÃ³n usa las MISMAS tÃ©cnicas que ARIA")
    print("ğŸ“¡ Se conecta a internet en tiempo real")
    print("ğŸ” Extrae informaciÃ³n real de fuentes pÃºblicas")
    print("ğŸ’¾ Muestra cÃ³mo se almacenarÃ­a la informaciÃ³n")
    
    resultados = []
    
    # Probar cada conexiÃ³n
    resultados.append(("Wikipedia", demo_wikipedia_connection()))
    resultados.append(("RSS Feeds", demo_rss_connection()))
    resultados.append(("ArXiv", demo_arxiv_connection()))
    
    # Mostrar flujo
    mostrar_flujo_completo()
    
    # Resumen final
    print("\n" + "=" * 60)
    print("ğŸ“Š RESUMEN DE DEMOSTRACIONES")
    print("=" * 60)
    
    exitosas = 0
    for fuente, resultado in resultados:
        status = "âœ… EXITOSA" if resultado else "âŒ FALLÃ“"
        print(f"{status:<12} {fuente}")
        if resultado:
            exitosas += 1
    
    print(f"\nğŸ¯ Resultado: {exitosas}/{len(resultados)} conexiones exitosas")
    
    if exitosas > 0:
        print("\nğŸ‰ Â¡DEMOSTRACIÃ“N EXITOSA!")
        print("âœ… ARIA puede conectarse realmente a internet")
        print("âœ… Extrae informaciÃ³n de fuentes verificadas")
        print("âœ… Procesa datos en tiempo real")
        print("âœ… Almacena conocimiento estructurado")
        print("\nğŸš€ Â¡No es simulaciÃ³n - es conocimiento REAL!")
    else:
        print("\nâš ï¸ Algunas conexiones fallaron")
        print("ğŸ’¡ Posibles causas: problemas de red, APIs temporalmente no disponibles")
        print("ğŸ”§ ARIA estÃ¡ configurado para manejar estos errores automÃ¡ticamente")

if __name__ == "__main__":
    main()