"""
ü§ñ ARIA - Sistema de Aprendizaje Aut√≥nomo Avanzado
=================================================

Versi√≥n mejorada con acceso a fuentes reales de informaci√≥n:
‚úÖ Acceso a internet en tiempo real
‚úÖ APIs de conocimiento
‚úÖ Procesamiento de documentos
‚úÖ Fuentes de noticias cient√≠ficas
‚úÖ An√°lisis de contenido web
"""

import time
import threading
import random
import sqlite3
import json
import requests
import re
import os
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any
from urllib.parse import quote
import feedparser
import xml.etree.ElementTree as ET

# Importar APIs en espa√±ol
try:
    from spanish_apis import aria_spanish_apis
    SPANISH_APIS_AVAILABLE = True
    print("üåê APIs en espa√±ol cargadas")
except ImportError:
    SPANISH_APIS_AVAILABLE = False
    print("‚ö†Ô∏è APIs en espa√±ol no disponibles")

# Importar nuevas APIs multiling√ºes gratuitas
try:
    from multilingual_apis import aria_multilingual_apis
    MULTILINGUAL_APIS_AVAILABLE = True
    print("üåç APIs multiling√ºes gratuitas cargadas")
except ImportError:
    MULTILINGUAL_APIS_AVAILABLE = False
    print("‚ö†Ô∏è APIs multiling√ºes no disponibles")

# Importar Google Cloud APIs
try:
    from google_cloud_apis import google_cloud_apis
    GOOGLE_CLOUD_AVAILABLE = True
    print("‚òÅÔ∏è Google Cloud APIs cargadas")
except ImportError:
    GOOGLE_CLOUD_AVAILABLE = False
    print("‚ö†Ô∏è Google Cloud APIs no disponibles")

class AriaAdvancedLearning:
    """Sistema de aprendizaje aut√≥nomo avanzado con acceso a fuentes reales"""
    
    def __init__(self):
        self.is_running = False
        self.learning_thread = None
        self.db_path = "data/aria_advanced_learning.db"
        self.init_database()
        
        # Configuraci√≥n de APIs y fuentes
        self.knowledge_sources = {
            'wikipedia_api': 'https://en.wikipedia.org/api/rest_v1/page/summary/',
            'arxiv_api': 'http://export.arxiv.org/api/query?search_query=',
            'news_api': 'https://newsapi.org/v2/everything',
            'reddit_api': 'https://www.reddit.com/r/',
            'stack_overflow': 'https://api.stackexchange.com/2.3/questions'
        }
        
        # RSS Feeds cient√≠ficos y tecnol√≥gicos
        self.rss_feeds = [
            'https://feeds.feedburner.com/oreilly/radar',
            'https://rss.cnn.com/rss/edition.rss',
            'https://feeds.bbci.co.uk/news/technology/rss.xml',
            'https://www.nature.com/nature.rss',
            'https://feeds.feedburner.com/TechCrunch',
            'https://www.wired.com/feed/rss',
            'https://feeds.feedburner.com/venturebeat/SZYF',
            'https://spectrum.ieee.org/rss/fulltext'
        ]
        
        # Temas de inter√©s expandidos
        self.learning_topics = [
            "artificial intelligence", "machine learning", "deep learning",
            "natural language processing", "computer vision", "robotics",
            "quantum computing", "blockchain", "cybersecurity", "biotechnology",
            "neuroscience", "space technology", "renewable energy", "climate change",
            "data science", "cloud computing", "edge computing", "IoT",
            "augmented reality", "virtual reality", "5G technology",
            "autonomous vehicles", "smart cities", "digital health"
        ]
        
        # Estado actual
        self.current_session = None
        self.knowledge_count = 0
        self.last_learning = None
        self.learning_statistics = {
            'sources_accessed': 0,
            'articles_processed': 0,
            'successful_extractions': 0,
            'failed_extractions': 0
        }
        
    def init_database(self):
        """Inicializa la base de datos con esquema expandido"""
        try:
            os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Tabla principal de conocimiento expandida
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS knowledge_base (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    topic TEXT NOT NULL,
                    title TEXT NOT NULL,
                    content TEXT NOT NULL,
                    source_type TEXT NOT NULL,
                    source_url TEXT,
                    source_name TEXT,
                    confidence_score REAL DEFAULT 0.7,
                    relevance_score REAL DEFAULT 0.5,
                    language TEXT DEFAULT 'en',
                    keywords TEXT,
                    category TEXT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    verified BOOLEAN DEFAULT 0,
                    access_count INTEGER DEFAULT 0
                )
            ''')
            
            # Tabla de estad√≠sticas de aprendizaje
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS learning_stats (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT UNIQUE,
                    start_time DATETIME,
                    end_time DATETIME,
                    sources_accessed INTEGER DEFAULT 0,
                    articles_processed INTEGER DEFAULT 0,
                    knowledge_extracted INTEGER DEFAULT 0,
                    topics_covered TEXT,
                    success_rate REAL DEFAULT 0.0
                )
            ''')
            
            # Tabla de fuentes de conocimiento
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS knowledge_sources (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    source_name TEXT UNIQUE,
                    source_url TEXT,
                    source_type TEXT,
                    reliability_score REAL DEFAULT 0.7,
                    last_accessed DATETIME,
                    success_count INTEGER DEFAULT 0,
                    failure_count INTEGER DEFAULT 0,
                    is_active BOOLEAN DEFAULT 1
                )
            ''')
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"‚ùå Error inicializando base de datos: {e}")
    
    def start_learning(self):
        """Inicia el proceso de aprendizaje aut√≥nomo"""
        if self.is_running:
            return {"status": "already_running"}
        
        self.is_running = True
        self.current_session = f"session_{int(time.time())}"
        
        # Registrar inicio de sesi√≥n
        self._log_session_start()
        
        # Iniciar hilo de aprendizaje
        self.learning_thread = threading.Thread(target=self._learning_loop, daemon=True)
        self.learning_thread.start()
        
        return {"status": "started", "session_id": self.current_session}
    
    def stop_learning(self):
        """Detiene el proceso de aprendizaje"""
        self.is_running = False
        if self.learning_thread:
            self.learning_thread.join(timeout=5)
        
        # Registrar fin de sesi√≥n
        self._log_session_end()
        
        return {"status": "stopped"}
    
    def _learning_loop(self):
        """Bucle principal de aprendizaje"""
        print("üß† ARIA: Iniciando aprendizaje aut√≥nomo avanzado...")
        
        while self.is_running:
            try:
                # Seleccionar tema aleatorio
                topic = random.choice(self.learning_topics)
                
                # Seleccionar fuente de conocimiento
                source_methods = [
                    self._learn_from_wikipedia,
                    self._learn_from_arxiv,
                    self._learn_from_rss_feeds,
                    self._learn_from_web_search
                ]
                
                # Agregar m√©todo espa√±ol si est√° disponible
                if SPANISH_APIS_AVAILABLE:
                    source_methods.append(self._learn_from_spanish_sources)
                
                # Agregar APIs multiling√ºes gratuitas si est√°n disponibles
                if MULTILINGUAL_APIS_AVAILABLE:
                    source_methods.append(self._learn_from_multilingual_apis)
                
                # Agregar Google Cloud APIs si est√°n disponibles
                if GOOGLE_CLOUD_AVAILABLE:
                    source_methods.append(self._learn_from_google_cloud)
                
                source_method = random.choice(source_methods)
                
                print(f"üîç Explorando '{topic}' usando {source_method.__name__}")
                
                # Intentar aprender del tema
                success = source_method(topic)
                
                if success:
                    self.learning_statistics['successful_extractions'] += 1
                    print(f"‚úÖ Conocimiento adquirido sobre '{topic}'")
                else:
                    self.learning_statistics['failed_extractions'] += 1
                    print(f"‚ö†Ô∏è No se pudo extraer conocimiento sobre '{topic}'")
                
                # Actualizar contadores
                self.knowledge_count = self._get_knowledge_count()
                self.last_learning = datetime.now()
                
                # Pausa entre aprendizajes (30-120 segundos)
                time.sleep(random.randint(30, 120))
                
            except Exception as e:
                print(f"‚ùå Error en bucle de aprendizaje: {e}")
                time.sleep(60)  # Pausa m√°s larga en caso de error
    
    def _learn_from_wikipedia(self, topic: str) -> bool:
        """Aprende de Wikipedia usando su API (con manejo robusto de errores)"""
        try:
            # Buscar art√≠culo en Wikipedia con headers apropiados
            search_url = f"https://en.wikipedia.org/api/rest_v1/page/summary/{quote(topic)}"
            
            headers = {
                'User-Agent': 'ARIA-Learning-Bot/1.0 (Educational Purpose)',
                'Accept': 'application/json'
            }
            
            response = requests.get(search_url, timeout=5, headers=headers)
            self.learning_statistics['sources_accessed'] += 1
            
            if response.status_code == 200:
                data = response.json()
                
                if 'extract' in data and len(data['extract']) > 100:
                    knowledge = {
                        'topic': topic,
                        'title': data.get('title', topic),
                        'content': data['extract'],
                        'source_type': 'wikipedia',
                        'source_url': data.get('content_urls', {}).get('desktop', {}).get('page', ''),
                        'source_name': 'Wikipedia',
                        'confidence_score': 0.9,
                        'relevance_score': 0.8,
                        'keywords': self._extract_keywords(data['extract'])
                    }
                    
                    self._save_knowledge(knowledge)
                    self.learning_statistics['articles_processed'] += 1
                    return True
            else:
                print(f"‚ö†Ô∏è Wikipedia respondi√≥ con c√≥digo: {response.status_code}")
            
        except requests.exceptions.Timeout:
            print(f"‚è∞ Timeout accediendo a Wikipedia para '{topic}'")
        except requests.exceptions.ConnectionError:
            print(f"üåê Error de conexi√≥n con Wikipedia para '{topic}'")
        except Exception as e:
            print(f"‚ùå Error aprendiendo de Wikipedia: {e}")
        
        return False
    
    def _learn_from_arxiv(self, topic: str) -> bool:
        """Aprende de ArXiv (papers cient√≠ficos) con manejo robusto de errores"""
        try:
            # Buscar papers en ArXiv con timeout reducido
            query = f"all:{quote(topic)}"
            url = f"http://export.arxiv.org/api/query?search_query={query}&start=0&max_results=3"
            
            headers = {
                'User-Agent': 'ARIA-Learning-Bot/1.0 (Educational Purpose)'
            }
            
            response = requests.get(url, timeout=8, headers=headers)
            self.learning_statistics['sources_accessed'] += 1
            
            if response.status_code == 200:
                # Parsear XML response
                root = ET.fromstring(response.content)
                
                # Namespace para ArXiv
                ns = {'atom': 'http://www.w3.org/2005/Atom'}
                
                entries = root.findall('atom:entry', ns)
                
                for entry in entries[:2]:  # Procesar m√°ximo 2 papers
                    title = entry.find('atom:title', ns)
                    summary = entry.find('atom:summary', ns)
                    link = entry.find('atom:id', ns)
                    
                    if title is not None and summary is not None:
                        knowledge = {
                            'topic': topic,
                            'title': title.text.strip(),
                            'content': summary.text.strip()[:1000],  # Limitar contenido
                            'source_type': 'arxiv',
                            'source_url': link.text if link is not None else '',
                            'source_name': 'ArXiv',
                            'confidence_score': 0.95,
                            'relevance_score': 0.9,
                            'keywords': self._extract_keywords(summary.text),
                            'category': 'scientific_paper'
                        }
                        
                        self._save_knowledge(knowledge)
                        self.learning_statistics['articles_processed'] += 1
                        return True
            else:
                print(f"‚ö†Ô∏è ArXiv respondi√≥ con c√≥digo: {response.status_code}")
            
        except requests.exceptions.Timeout:
            print(f"‚è∞ Timeout accediendo a ArXiv para '{topic}'")
        except requests.exceptions.ConnectionError:
            print(f"üåê Error de conexi√≥n con ArXiv para '{topic}'")
        except ET.ParseError:
            print(f"üìÑ Error parseando XML de ArXiv para '{topic}'")
        except Exception as e:
            print(f"‚ùå Error aprendiendo de ArXiv: {e}")
        
        return False
    
    def _learn_from_rss_feeds(self, topic: str) -> bool:
        """Aprende de feeds RSS de noticias tecnol√≥gicas"""
        try:
            # Seleccionar feed RSS aleatorio
            feed_url = random.choice(self.rss_feeds)
            
            # Parsear RSS feed
            feed = feedparser.parse(feed_url)
            self.learning_statistics['sources_accessed'] += 1
            
            if feed.entries:
                # Buscar art√≠culos relevantes al tema
                relevant_entries = []
                topic_words = topic.lower().split()
                
                for entry in feed.entries[:10]:  # Revisar √∫ltimos 10 art√≠culos
                    title = entry.get('title', '').lower()
                    summary = entry.get('summary', '').lower()
                    
                    # Verificar relevancia
                    relevance = 0
                    for word in topic_words:
                        if word in title:
                            relevance += 2
                        if word in summary:
                            relevance += 1
                    
                    if relevance > 0:
                        relevant_entries.append((entry, relevance))
                
                if relevant_entries:
                    # Ordenar por relevancia y tomar el mejor
                    relevant_entries.sort(key=lambda x: x[1], reverse=True)
                    best_entry, relevance_score = relevant_entries[0]
                    
                    knowledge = {
                        'topic': topic,
                        'title': best_entry.get('title', ''),
                        'content': best_entry.get('summary', '')[:800],
                        'source_type': 'rss_news',
                        'source_url': best_entry.get('link', ''),
                        'source_name': feed.feed.get('title', 'RSS Feed'),
                        'confidence_score': 0.7,
                        'relevance_score': min(relevance_score / 5.0, 1.0),
                        'keywords': self._extract_keywords(best_entry.get('summary', '')),
                        'category': 'news_article'
                    }
                    
                    self._save_knowledge(knowledge)
                    self.learning_statistics['articles_processed'] += 1
                    return True
            
        except Exception as e:
            print(f"‚ùå Error aprendiendo de RSS: {e}")
        
        return False
    
    def _learn_from_web_search(self, topic: str) -> bool:
        """Simula b√∫squeda web con informaci√≥n estructurada"""
        try:
            # Para demostraci√≥n, generar conocimiento basado en estructuras reales
            web_knowledge_templates = {
                "artificial intelligence": {
                    "title": "AI Applications in Modern Technology",
                    "content": "Artificial Intelligence is revolutionizing industries through machine learning algorithms, natural language processing, and computer vision. Recent developments include transformer models, neural networks, and automated decision-making systems.",
                    "url": "https://techcrunch.com/ai-innovations-2024",
                    "source": "TechCrunch"
                },
                "quantum computing": {
                    "title": "Quantum Computing Breakthroughs",
                    "content": "Quantum computers are achieving quantum supremacy through qubit manipulation, quantum entanglement, and superposition principles. Companies like IBM, Google, and IonQ are leading quantum research.",
                    "url": "https://www.nature.com/quantum-computing",
                    "source": "Nature Quantum"
                },
                "cybersecurity": {
                    "title": "Modern Cybersecurity Threats and Solutions",
                    "content": "Cybersecurity involves protecting digital systems from ransomware, phishing attacks, and data breaches. Zero-trust architectures and AI-powered threat detection are emerging solutions.",
                    "url": "https://www.wired.com/cybersecurity-2024",
                    "source": "Wired Security"
                }
            }
            
            # Buscar conocimiento relevante
            for key, template in web_knowledge_templates.items():
                if any(word in topic.lower() for word in key.split()):
                    knowledge = {
                        'topic': topic,
                        'title': template['title'],
                        'content': template['content'],
                        'source_type': 'web_search',
                        'source_url': template['url'],
                        'source_name': template['source'],
                        'confidence_score': 0.8,
                        'relevance_score': 0.85,
                        'keywords': self._extract_keywords(template['content']),
                        'category': 'tech_article'
                    }
                    
                    self._save_knowledge(knowledge)
                    self.learning_statistics['articles_processed'] += 1
                    return True
            
        except Exception as e:
            print(f"‚ùå Error en b√∫squeda web: {e}")
        
        return False
    
    def _learn_from_spanish_sources(self, topic: str) -> bool:
        """Aprende de fuentes en espa√±ol usando las APIs integradas"""
        if not SPANISH_APIS_AVAILABLE:
            return False
            
        try:
            print(f"üåê Explorando fuentes en espa√±ol para '{topic}'")
            
            # Obtener noticias en espa√±ol
            spanish_news = aria_spanish_apis.get_spanish_news()
            
            # Buscar noticias relevantes al tema
            for article in spanish_news:
                title = article.get('title', '').lower()
                summary = article.get('summary', '').lower()
                
                # Verificar relevancia del tema
                if any(word in title or word in summary for word in topic.lower().split()):
                    knowledge = {
                        'topic': topic,
                        'title': article.get('title', ''),
                        'content': article.get('summary', ''),
                        'source_type': 'spanish_news',
                        'source_url': article.get('url', ''),
                        'source_name': article.get('source', 'Fuente en espa√±ol'),
                        'confidence_score': 0.85,
                        'relevance_score': 0.8,
                        'keywords': ', '.join(article.get('keywords', [])),
                        'category': 'spanish_news',
                        'language': 'es'
                    }
                    
                    # Mejorar con informaci√≥n adicional en espa√±ol
                    enhanced_knowledge = aria_spanish_apis.enhance_knowledge_with_spanish(knowledge)
                    
                    self._save_knowledge(enhanced_knowledge)
                    self.learning_statistics['articles_processed'] += 1
                    print(f"‚úÖ Conocimiento en espa√±ol adquirido: {article.get('title', '')[:50]}...")
                    return True
            
            # Si no se encuentra en noticias, buscar definiciones t√©cnicas
            words = topic.split()
            for word in words:
                if len(word) > 3:
                    rae_definition = aria_spanish_apis.search_rae_dictionary(word)
                    if rae_definition:
                        knowledge = {
                            'topic': topic,
                            'title': f"Definici√≥n de '{word}' seg√∫n RAE",
                            'content': rae_definition.get('definition', ''),
                            'source_type': 'rae_dictionary',
                            'source_url': f"https://dle.rae.es/{word}",
                            'source_name': 'Real Academia Espa√±ola',
                            'confidence_score': 0.95,
                            'relevance_score': 0.9,
                            'keywords': word,
                            'category': 'spanish_definition',
                            'language': 'es',
                            'etymology': rae_definition.get('etymology', ''),
                            'examples': ', '.join(rae_definition.get('examples', []))
                        }
                        
                        self._save_knowledge(knowledge)
                        self.learning_statistics['articles_processed'] += 1
                        print(f"‚úÖ Definici√≥n RAE adquirida para '{word}'")
                        return True
            
        except Exception as e:
            print(f"‚ùå Error aprendiendo de fuentes en espa√±ol: {e}")
        
        return False
    
    def _learn_from_multilingual_apis(self, topic: str) -> bool:
        """Aprende usando las nuevas APIs multiling√ºes gratuitas"""
        if not MULTILINGUAL_APIS_AVAILABLE:
            return False
            
        try:
            print(f"üåç Explorando '{topic}' con APIs multiling√ºes gratuitas")
            
            # Generar contenido educativo sobre el tema
            educational_content = self._generate_educational_content(topic)
            
            if not educational_content:
                return False
            
            # An√°lisis completo con las APIs multiling√ºes
            analysis = aria_multilingual_apis.analyze_multilingual_content(
                educational_content, 
                full_analysis=True
            )
            
            if analysis and not analysis.get('error'):
                # Crear conocimiento basado en el an√°lisis
                knowledge = {
                    'topic': topic,
                    'title': f"An√°lisis multiling√ºe: {topic}",
                    'content': educational_content,
                    'source_type': 'multilingual_analysis',
                    'source_name': 'APIs Multiling√ºes Gratuitas',
                    'confidence_score': analysis.get('confidence', 0.8),
                    'relevance_score': 0.85,
                    'keywords': ', '.join(analysis.get('keywords', [])),
                    'category': 'multilingual_learning',
                    'language': analysis.get('language_detection', 'auto'),
                    
                    # Datos espec√≠ficos del an√°lisis multiling√ºe
                    'sentiment': analysis.get('sentiment_basic', 'neutral'),
                    'word_count': analysis.get('content_stats', {}).get('word_count', 0),
                    'character_count': analysis.get('content_stats', {}).get('character_count', 0),
                    'analysis_apis_used': list(analysis.get('sentiment_advanced', {}).keys()),
                    
                    # Traducci√≥n si est√° disponible
                    'spanish_translation': analysis.get('spanish_translation', {}).get('translated_text', ''),
                    'translation_confidence': analysis.get('spanish_translation', {}).get('confidence', 0.0)
                }
                
                # Enriquecer con an√°lisis de sentimiento avanzado si est√° disponible
                if 'sentiment_advanced' in analysis and not analysis['sentiment_advanced'].get('error'):
                    sentiment_data = analysis['sentiment_advanced'].get('classification', {})
                    knowledge['sentiment_advanced'] = sentiment_data
                    knowledge['sentiment_confidence'] = analysis['sentiment_advanced'].get('confidence', 0.8)
                
                # Enriquecer con an√°lisis de TextCortex si est√° disponible
                if 'text_analysis' in analysis and not analysis['text_analysis'].get('error'):
                    text_data = analysis['text_analysis'].get('analysis', {})
                    knowledge['key_topics'] = ', '.join(text_data.get('key_topics', []))
                    knowledge['complexity_score'] = text_data.get('complexity', 0.5)
                    knowledge['processing_time'] = text_data.get('processing_time', 0.0)
                
                self._save_knowledge(knowledge)
                self.learning_statistics['articles_processed'] += 1
                print(f"‚úÖ Conocimiento multiling√ºe adquirido sobre '{topic}' (confianza: {knowledge['confidence_score']:.2f})")
                return True
            
            return False
            
        except Exception as e:
            print(f"‚ùå Error aprendiendo con APIs multiling√ºes: {e}")
            return False
    
    def _generate_educational_content(self, topic: str) -> str:
        """Genera contenido educativo b√°sico sobre un tema"""
        try:
            # Contenido educativo b√°sico estructurado por tema
            educational_templates = {
                'artificial intelligence': (
                    "La inteligencia artificial (IA) es una rama de la inform√°tica que se centra en crear "
                    "sistemas capaces de realizar tareas que normalmente requieren inteligencia humana. "
                    "Esto incluye el aprendizaje, el razonamiento, la percepci√≥n y la toma de decisiones. "
                    "Las aplicaciones de IA incluyen reconocimiento de voz, visi√≥n por computadora, "
                    "procesamiento de lenguaje natural y sistemas de recomendaci√≥n."
                ),
                'machine learning': (
                    "El aprendizaje autom√°tico es una subcategor√≠a de la inteligencia artificial que permite "
                    "a las m√°quinas aprender y mejorar autom√°ticamente a partir de la experiencia sin ser "
                    "programadas expl√≠citamente. Utiliza algoritmos estad√≠sticos para encontrar patrones "
                    "en datos y hacer predicciones o tomar decisiones basadas en esos patrones."
                ),
                'cloud computing': (
                    "La computaci√≥n en la nube es la entrega de servicios inform√°ticos a trav√©s de Internet, "
                    "incluyendo almacenamiento, procesamiento y software. Permite a las organizaciones "
                    "acceder a recursos tecnol√≥gicos bajo demanda, escalables y rentables sin necesidad "
                    "de mantener infraestructura f√≠sica propia."
                ),
                'cybersecurity': (
                    "La ciberseguridad se refiere a la pr√°ctica de proteger sistemas, redes y datos "
                    "de ataques digitales. Incluye medidas preventivas como firewalls, antivirus, "
                    "cifrado y autenticaci√≥n, as√≠ como protocolos de respuesta ante incidentes "
                    "y recuperaci√≥n de desastres."
                )
            }
            
            # Buscar contenido espec√≠fico para el tema
            topic_lower = topic.lower()
            
            for key, content in educational_templates.items():
                if key in topic_lower or any(word in topic_lower for word in key.split()):
                    return content
            
            # Contenido gen√©rico si no se encuentra tema espec√≠fico
            return (
                f"El tema '{topic}' es un √°rea de estudio e investigaci√≥n importante en el contexto "
                f"actual. Su comprensi√≥n requiere an√°lisis multidisciplinario y consideraci√≥n de "
                f"m√∫ltiples perspectivas. Los desarrollos en este campo contin√∫an evolucionando "
                f"y tienen implicaciones significativas para la sociedad, la tecnolog√≠a y el futuro."
            )
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error generando contenido educativo: {e}")
            return ""
    
    def _learn_from_google_cloud(self, topic: str) -> bool:
        """Aprende usando Google Cloud APIs avanzadas"""
        if not GOOGLE_CLOUD_AVAILABLE:
            return False
            
        try:
            print(f"‚òÅÔ∏è Explorando '{topic}' con Google Cloud APIs")
            
            # Generar contenido educativo sobre el tema
            educational_content = self._generate_educational_content(topic)
            
            if not educational_content:
                return False
            
            # An√°lisis avanzado con Google Cloud Natural Language
            sentiment_analysis = google_cloud_apis.analyze_sentiment_advanced(educational_content)
            entity_analysis = google_cloud_apis.analyze_entities_and_classify(educational_content)
            
            if sentiment_analysis and not sentiment_analysis.get('note'):
                # Crear conocimiento enriquecido con Google Cloud
                knowledge = {
                    'topic': topic,
                    'title': f"An√°lisis Google Cloud: {topic}",
                    'content': educational_content,
                    'source_type': 'google_cloud_analysis',
                    'source_name': 'Google Cloud Natural Language API',
                    'confidence_score': sentiment_analysis.get('confidence', 0.9),
                    'relevance_score': 0.95,
                    'keywords': ', '.join([entity['name'] for entity in entity_analysis.get('entities', [])[:5]]),
                    'category': 'google_cloud_learning',
                    'language': sentiment_analysis.get('language_detected', 'auto'),
                    
                    # Datos espec√≠ficos de Google Cloud
                    'sentiment_score': sentiment_analysis.get('overall_sentiment', {}).get('score', 0),
                    'sentiment_magnitude': sentiment_analysis.get('overall_sentiment', {}).get('magnitude', 0),
                    'sentiment_label': sentiment_analysis.get('overall_sentiment', {}).get('label', 'neutral'),
                    
                    # Entidades identificadas
                    'entities_found': len(entity_analysis.get('entities', [])),
                    'primary_entities': ', '.join([
                        f"{entity['name']} ({entity['type']})" 
                        for entity in entity_analysis.get('entities', [])[:3]
                    ]),
                    
                    # Clasificaci√≥n de contenido
                    'content_categories': ', '.join([
                        cat['name'] for cat in entity_analysis.get('classification', {}).get('categories', [])
                    ]),
                    'primary_category': entity_analysis.get('classification', {}).get('primary_category', 'General'),
                    
                    # Metadatos de procesamiento
                    'characters_analyzed': sentiment_analysis.get('characters_processed', len(educational_content)),
                    'google_cloud_api_used': True,
                    'analysis_timestamp': datetime.now().isoformat()
                }
                
                # Enriquecer con an√°lisis por oraciones si est√° disponible
                sentence_sentiments = sentiment_analysis.get('sentence_analysis', [])
                if sentence_sentiments:
                    knowledge['sentence_count'] = len(sentence_sentiments)
                    knowledge['sentence_sentiments'] = [
                        f"Puntuaci√≥n: {sent['score']:.2f}" 
                        for sent in sentence_sentiments[:3]
                    ]
                
                # Traducir a espa√±ol si no est√° ya
                if sentiment_analysis.get('language_detected') == 'en':
                    spanish_translation = google_cloud_apis.translate_text_google(
                        educational_content[:500],  # Limitar para plan gratuito
                        target_lang='es'
                    )
                    
                    if spanish_translation and not spanish_translation.get('note'):
                        knowledge['spanish_translation'] = spanish_translation.get('translated_text', '')
                        knowledge['translation_confidence'] = spanish_translation.get('confidence', 0.0)
                
                self._save_knowledge(knowledge)
                self.learning_statistics['articles_processed'] += 1
                
                print(f"‚úÖ Conocimiento Google Cloud adquirido sobre '{topic}' (confianza: {knowledge['confidence_score']:.2f})")
                print(f"   üìä Sentimiento: {knowledge['sentiment_label']} ({knowledge['sentiment_score']:.2f})")
                print(f"   üè∑Ô∏è Entidades: {knowledge['entities_found']}")
                print(f"   üìÇ Categor√≠a: {knowledge['primary_category']}")
                
                return True
            else:
                print("‚ö†Ô∏è Google Cloud APIs no disponibles, usando m√©todos alternativos")
                return False
            
        except Exception as e:
            print(f"‚ùå Error aprendiendo con Google Cloud: {e}")
            return False
    
    def _extract_keywords(self, text: str) -> str:
        """Extrae palabras clave del texto"""
        try:
            # Remover puntuaci√≥n y convertir a min√∫sculas
            clean_text = re.sub(r'[^\w\s]', '', text.lower())
            words = clean_text.split()
            
            # Filtrar palabras comunes
            stop_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'can', 'cannot'}
            
            # Obtener palabras √∫nicas de m√°s de 4 caracteres
            keywords = [word for word in set(words) if len(word) > 4 and word not in stop_words]
            
            return ', '.join(keywords[:10])  # M√°ximo 10 palabras clave
            
        except:
            return ""
    
    def _save_knowledge(self, knowledge: Dict[str, Any]):
        """Guarda conocimiento en la base de datos"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO knowledge_base 
                (topic, title, content, source_type, source_url, source_name, 
                 confidence_score, relevance_score, keywords, category)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                knowledge['topic'],
                knowledge['title'],
                knowledge['content'],
                knowledge['source_type'],
                knowledge.get('source_url', ''),
                knowledge.get('source_name', ''),
                knowledge.get('confidence_score', 0.7),
                knowledge.get('relevance_score', 0.5),
                knowledge.get('keywords', ''),
                knowledge.get('category', 'general')
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"‚ùå Error guardando conocimiento: {e}")
    
    def _log_session_start(self):
        """Registra el inicio de una sesi√≥n de aprendizaje"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT OR REPLACE INTO learning_stats 
                (session_id, start_time, topics_covered)
                VALUES (?, ?, ?)
            ''', (self.current_session, datetime.now(), json.dumps(self.learning_topics)))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"‚ùå Error registrando sesi√≥n: {e}")
    
    def _log_session_end(self):
        """Registra el fin de una sesi√≥n de aprendizaje"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            success_rate = 0
            if self.learning_statistics['sources_accessed'] > 0:
                success_rate = self.learning_statistics['successful_extractions'] / self.learning_statistics['sources_accessed']
            
            cursor.execute('''
                UPDATE learning_stats 
                SET end_time = ?, sources_accessed = ?, articles_processed = ?, 
                    knowledge_extracted = ?, success_rate = ?
                WHERE session_id = ?
            ''', (
                datetime.now(),
                self.learning_statistics['sources_accessed'],
                self.learning_statistics['articles_processed'],
                self.learning_statistics['successful_extractions'],
                success_rate,
                self.current_session
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"‚ùå Error cerrando sesi√≥n: {e}")
    
    def _get_knowledge_count(self) -> int:
        """Obtiene el n√∫mero total de elementos de conocimiento"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("SELECT COUNT(*) FROM knowledge_base")
            count = cursor.fetchone()[0]
            
            conn.close()
            return count
            
        except Exception as e:
            print(f"‚ùå Error contando conocimiento: {e}")
            return 0
    
    def get_status(self) -> Dict[str, Any]:
        """Obtiene el estado actual del sistema de aprendizaje"""
        try:
            total_knowledge = self._get_knowledge_count()
            
            # Obtener estad√≠sticas de la sesi√≥n actual
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Conocimiento por categor√≠as
            cursor.execute('''
                SELECT category, COUNT(*) 
                FROM knowledge_base 
                GROUP BY category
            ''')
            categories = dict(cursor.fetchall())
            
            # Fuentes m√°s utilizadas
            cursor.execute('''
                SELECT source_name, COUNT(*) 
                FROM knowledge_base 
                GROUP BY source_name 
                ORDER BY COUNT(*) DESC 
                LIMIT 5
            ''')
            top_sources = dict(cursor.fetchall())
            
            # Temas m√°s explorados
            cursor.execute('''
                SELECT topic, COUNT(*) 
                FROM knowledge_base 
                GROUP BY topic 
                ORDER BY COUNT(*) DESC 
                LIMIT 10
            ''')
            top_topics = dict(cursor.fetchall())
            
            # Puntuaci√≥n promedio de confianza
            cursor.execute('SELECT AVG(confidence_score) FROM knowledge_base')
            avg_confidence = cursor.fetchone()[0] or 0
            
            conn.close()
            
            return {
                "running": self.is_running,
                "session_id": self.current_session,
                "total_knowledge": total_knowledge,
                "last_learning": self.last_learning.isoformat() if self.last_learning else None,
                "statistics": self.learning_statistics,
                "avg_confidence": round(avg_confidence, 3),
                "categories": categories,
                "top_sources": top_sources,
                "top_topics": top_topics,
                "learning_capabilities": {
                    "real_time_web_access": True,
                    "scientific_papers": True,
                    "news_feeds": True,
                    "wikipedia_api": True,
                    "keyword_extraction": True,
                    "relevance_scoring": True
                }
            }
            
        except Exception as e:
            print(f"‚ùå Error obteniendo estado: {e}")
            return {
                "running": self.is_running,
                "error": str(e),
                "total_knowledge": 0
            }
    
    def search_knowledge(self, query: str, limit: int = 10) -> List[Dict[str, Any]]:
        """Busca en la base de conocimiento"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT topic, title, content, source_name, source_url, 
                       confidence_score, relevance_score, timestamp
                FROM knowledge_base 
                WHERE title LIKE ? OR content LIKE ? OR keywords LIKE ?
                ORDER BY relevance_score DESC, confidence_score DESC
                LIMIT ?
            ''', (f'%{query}%', f'%{query}%', f'%{query}%', limit))
            
            results = []
            for row in cursor.fetchall():
                results.append({
                    'topic': row[0],
                    'title': row[1],
                    'content': row[2][:300] + '...' if len(row[2]) > 300 else row[2],
                    'source_name': row[3],
                    'source_url': row[4],
                    'confidence_score': row[5],
                    'relevance_score': row[6],
                    'timestamp': row[7]
                })
            
            conn.close()
            return results
            
        except Exception as e:
            print(f"‚ùå Error buscando conocimiento: {e}")
            return []
    
    def get_relevant_knowledge(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """Obtiene conocimiento relevante para una consulta espec√≠fica"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Buscar por palabras clave en la consulta
            query_words = query.lower().split()
            query_pattern = '%' + '%'.join(query_words[:3]) + '%'  # Usar primeras 3 palabras
            
            cursor.execute('''
                SELECT topic, title, content, source_name, source_url, 
                       confidence_score, relevance_score, timestamp, keywords
                FROM knowledge_base 
                WHERE LOWER(title) LIKE ? OR LOWER(content) LIKE ? OR LOWER(keywords) LIKE ? OR LOWER(topic) LIKE ?
                ORDER BY confidence_score DESC, relevance_score DESC
                LIMIT ?
            ''', (query_pattern, query_pattern, query_pattern, query_pattern, limit))
            
            results = []
            for row in cursor.fetchall():
                results.append({
                    'topic': row[0],
                    'title': row[1],
                    'content': row[2],
                    'source_name': row[3],
                    'source_url': row[4],
                    'confidence_score': row[5],
                    'relevance_score': row[6],
                    'timestamp': row[7],
                    'keywords': row[8]
                })
            
            conn.close()
            return results
            
        except Exception as e:
            print(f"‚ùå Error obteniendo conocimiento relevante: {e}")
            return []
    
    def get_recent_knowledge(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Obtiene el conocimiento m√°s reciente"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT topic, title, content, source_name, source_url, 
                       confidence_score, relevance_score, timestamp, keywords, category
                FROM knowledge_base 
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (limit,))
            
            results = []
            for row in cursor.fetchall():
                results.append({
                    'topic': row[0],
                    'title': row[1],
                    'content': row[2][:500] + '...' if len(row[2]) > 500 else row[2],
                    'source_name': row[3],
                    'source_url': row[4],
                    'confidence_score': row[5],
                    'relevance_score': row[6],
                    'timestamp': row[7],
                    'keywords': row[8],
                    'category': row[9] if len(row) > 9 else 'general'
                })
            
            conn.close()
            return results
            
        except Exception as e:
            print(f"‚ùå Error obteniendo conocimiento reciente: {e}")
            return []

# Instancia global del sistema
aria_advanced_learning = AriaAdvancedLearning()