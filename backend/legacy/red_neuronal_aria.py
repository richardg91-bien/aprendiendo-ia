"""
üß† RED NEURONAL AVANZADA PARA ARIA
Sistema de Deep Learning que aprende patrones complejos en conversaciones
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import json
import os
import re
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import SnowballStemmer
import pickle
from datetime import datetime
import matplotlib.pyplot as plt

# Descargar recursos de NLTK necesarios
try:
    nltk.download('punkt', quiet=True)
    nltk.download('stopwords', quiet=True)
    nltk.download('punkt_tab', quiet=True)
except:
    pass

class RedNeuronalARIA:
    def __init__(self):
        """Inicializa la red neuronal para ARIA"""
        self.model = None
        self.vectorizer = TfidfVectorizer(
            max_features=1000,
            ngram_range=(1, 3),
            stop_words='english'
        )
        self.label_encoder = LabelEncoder()
        self.scaler = StandardScaler()
        self.stemmer = SnowballStemmer('spanish')
        
        # Configuraci√≥n de la red
        self.config = {
            'vocab_size': 1000,
            'embedding_dim': 128,
            'hidden_units': [256, 128, 64],
            'dropout_rate': 0.3,
            'learning_rate': 0.001,
            'epochs': 50,
            'batch_size': 32
        }
        
        self.is_trained = False
        self.training_history = None
        
        # Cargar modelo si existe
        self.cargar_modelo_entrenado()
    
    def preprocesar_texto(self, texto):
        """Preprocesa el texto para el entrenamiento"""
        # Convertir a min√∫sculas
        texto = texto.lower()
        
        # Remover caracteres especiales
        texto = re.sub(r'[^a-z√°√©√≠√≥√∫√º√±\s]', ' ', texto)
        
        # Tokenizar
        tokens = word_tokenize(texto)
        
        # Remover stop words y aplicar stemming
        try:
            stop_words = set(stopwords.words('spanish'))
            tokens = [self.stemmer.stem(token) for token in tokens if token not in stop_words and len(token) > 2]
        except:
            tokens = [token for token in tokens if len(token) > 2]
        
        return ' '.join(tokens)
    
    def crear_arquitectura_red(self, input_dim, num_classes):
        """Crea la arquitectura de la red neuronal"""
        
        model = tf.keras.Sequential([
            # Capa de entrada
            tf.keras.layers.Input(shape=(input_dim,)),
            tf.keras.layers.Dense(64, activation='relu', name='entrada'),
            tf.keras.layers.Dropout(0.3),
            
            # Capa oculta
            tf.keras.layers.Dense(32, activation='relu', name='oculta'),
            tf.keras.layers.Dropout(0.3),
            
            # Capa de salida
            tf.keras.layers.Dense(num_classes, activation='softmax', name='salida')
        ])
        
        # Compilar modelo
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        
        return model
    
    def cargar_datos_conversaciones(self):
        """Carga y procesa datos de conversaciones"""
        
        datos_entrenamiento = []
        
        # Cargar desde archivo de memoria si existe
        if os.path.exists('memoria_conversaciones.json'):
            with open('memoria_conversaciones.json', 'r', encoding='utf-8') as f:
                memoria = json.load(f)
                
            conversaciones = memoria.get('conversaciones', [])
            
            for conv in conversaciones:
                pregunta = conv.get('pregunta', '')
                respuesta = conv.get('respuesta', '')
                calificacion = conv.get('calificacion')
                
                # Manejar calificaciones nulas o inv√°lidas
                if calificacion is None:
                    calificacion = 3
                try:
                    calificacion = float(calificacion)
                except (ValueError, TypeError):
                    calificacion = 3.0
                
                if pregunta and respuesta:
                    # Crear datos de entrenamiento
                    datos_entrenamiento.append({
                        'pregunta': pregunta,
                        'respuesta': respuesta,
                        'calificacion': calificacion,
                        'categoria': self._categorizar_pregunta(pregunta),
                        'sentimiento': self._analizar_sentimiento(calificacion)
                    })
        
        # Agregar datos sint√©ticos si hay pocos datos
        if len(datos_entrenamiento) < 20:
            datos_entrenamiento.extend(self._generar_datos_sinteticos())
        
        return pd.DataFrame(datos_entrenamiento)
    
    def _categorizar_pregunta(self, pregunta):
        """Categoriza autom√°ticamente las preguntas"""
        pregunta_lower = pregunta.lower()
        
        if any(palabra in pregunta_lower for palabra in ['hola', 'hey', 'buenos', 'saludos']):
            return 'saludo'
        elif any(palabra in pregunta_lower for palabra in ['hora', 'tiempo', 'qu√© hora']):
            return 'tiempo'
        elif any(palabra in pregunta_lower for palabra in ['fecha', 'd√≠a', 'hoy']):
            return 'fecha'
        elif any(palabra in pregunta_lower for palabra in ['chiste', 'gracioso', 'divertido']):
            return 'entretenimiento'
        elif any(palabra in pregunta_lower for palabra in ['programar', 'c√≥digo', 'python', 'javascript']):
            return 'programacion'
        elif any(palabra in pregunta_lower for palabra in ['c√≥mo est√°s', 'estado', 'funcionando']):
            return 'estado'
        elif any(palabra in pregunta_lower for palabra in ['ayuda', 'help', 'asistencia']):
            return 'ayuda'
        else:
            return 'general'
    
    def _analizar_sentimiento(self, calificacion):
        """Analiza el sentimiento basado en la calificaci√≥n"""
        if calificacion is None:
            calificacion = 3  # Valor por defecto
            
        try:
            calificacion = float(calificacion)
        except (ValueError, TypeError):
            calificacion = 3.0
            
        if calificacion >= 4:
            return 'positivo'
        elif calificacion <= 2:
            return 'negativo'
        else:
            return 'neutral'
    
    def _generar_datos_sinteticos(self):
        """Genera datos sint√©ticos para entrenar la red"""
        
        datos_sinteticos = [
            # Saludos
            {'pregunta': 'hola', 'respuesta': 'Hola, ¬øc√≥mo est√°s?', 'calificacion': 5, 'categoria': 'saludo', 'sentimiento': 'positivo'},
            {'pregunta': 'buenos d√≠as', 'respuesta': 'Buenos d√≠as, ¬øen qu√© puedo ayudarte?', 'calificacion': 5, 'categoria': 'saludo', 'sentimiento': 'positivo'},
            {'pregunta': 'hey', 'respuesta': 'Hey! Soy ARIA, tu asistente inteligente', 'calificacion': 4, 'categoria': 'saludo', 'sentimiento': 'positivo'},
            
            # Tiempo y fecha
            {'pregunta': 'qu√© hora es', 'respuesta': 'Son las 15:30', 'calificacion': 5, 'categoria': 'tiempo', 'sentimiento': 'positivo'},
            {'pregunta': 'fecha de hoy', 'respuesta': 'Hoy es 13 de octubre de 2025', 'calificacion': 5, 'categoria': 'fecha', 'sentimiento': 'positivo'},
            
            # Entretenimiento
            {'pregunta': 'cu√©ntame un chiste', 'respuesta': '¬øPor qu√© los programadores prefieren el modo oscuro? Porque la luz atrae bugs', 'calificacion': 4, 'categoria': 'entretenimiento', 'sentimiento': 'positivo'},
            
            # Programaci√≥n
            {'pregunta': 'c√≥mo programar en python', 'respuesta': 'Python es f√°cil de aprender. Empieza con variables y funciones', 'calificacion': 4, 'categoria': 'programacion', 'sentimiento': 'positivo'},
            {'pregunta': 'explicar variables', 'respuesta': 'Las variables guardan datos. Ejemplo: nombre = \"Juan\"', 'calificacion': 5, 'categoria': 'programacion', 'sentimiento': 'positivo'},
            
            # Estado y ayuda
            {'pregunta': 'c√≥mo est√°s', 'respuesta': 'Funcionando perfectamente, gracias por preguntar', 'calificacion': 4, 'categoria': 'estado', 'sentimiento': 'positivo'},
            {'pregunta': 'ayuda', 'respuesta': 'Puedo ayudarte con muchas cosas. ¬øQu√© necesitas?', 'calificacion': 4, 'categoria': 'ayuda', 'sentimiento': 'positivo'},
            
            # Casos negativos
            {'pregunta': 'no entiendo', 'respuesta': 'Lo siento, no puedo ayudarte', 'calificacion': 1, 'categoria': 'general', 'sentimiento': 'negativo'},
            {'pregunta': 'eres in√∫til', 'respuesta': 'Perd√≥n por no cumplir tus expectativas', 'calificacion': 1, 'categoria': 'general', 'sentimiento': 'negativo'},
        ]
        
        return datos_sinteticos
    
    def entrenar_red_neuronal(self):
        """Entrena la red neuronal con los datos disponibles"""
        
        print("üß† INICIANDO ENTRENAMIENTO DE RED NEURONAL...")
        
        # Cargar datos
        df = self.cargar_datos_conversaciones()
        print(f"üìä Datos cargados: {len(df)} conversaciones")
        
        if len(df) < 5:
            print("‚ùå Insuficientes datos para entrenamiento")
            return False
        
        # Preprocesar texto
        print("üî§ Preprocesando texto...")
        df['pregunta_procesada'] = df['pregunta'].apply(self.preprocesar_texto)
        
        # Vectorizar preguntas
        X_text = self.vectorizer.fit_transform(df['pregunta_procesada'])
        
        # Crear caracter√≠sticas adicionales
        caracteristicas_extra = []
        for _, row in df.iterrows():
            features = [
                len(row['pregunta']),  # Longitud
                row['calificacion'],   # Calificaci√≥n
                row['pregunta'].count('?'),  # N√∫mero de preguntas
                row['pregunta'].count('!'),  # N√∫mero de exclamaciones
            ]
            caracteristicas_extra.append(features)
        
        caracteristicas_extra = np.array(caracteristicas_extra)
        caracteristicas_extra = self.scaler.fit_transform(caracteristicas_extra)
        
        # Combinar caracter√≠sticas
        X = np.hstack([X_text.toarray(), caracteristicas_extra])
        
        # Preparar etiquetas (categor√≠as)
        y = self.label_encoder.fit_transform(df['categoria'])
        
        print(f"üìê Dimensiones de entrada: {X.shape}")
        print(f"üè∑Ô∏è Clases encontradas: {len(np.unique(y))}")
        
        # Dividir datos - ajustar seg√∫n cantidad de datos y clases
        num_classes = len(np.unique(y))
        min_samples_per_class = 2
        
        if len(X) > num_classes * min_samples_per_class * 2:
            # Suficientes datos para dividir con stratify
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )
        elif len(X) > num_classes * min_samples_per_class:
            # Dividir sin stratify
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
        else:
            # Muy pocos datos - usar todos para entrenamiento
            X_train, X_test, y_train, y_test = X, X, y, y
            print("‚ö†Ô∏è Pocos datos - usando conjunto completo para entrenamiento")
        
        # Crear y entrenar modelo
        print("üèóÔ∏è Construyendo arquitectura de red neuronal...")
        self.model = self.crear_arquitectura_red(X.shape[1], len(np.unique(y)))
        
        print("üìà Entrenando red neuronal...")
        
        # Callbacks para mejorar entrenamiento
        callbacks = [
            tf.keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=10,
                restore_best_weights=True
            ),
            tf.keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5
            )
        ]
        
        # Entrenar
        validation_data = (X_test, y_test) if len(X_test) > 0 else None
        
        self.training_history = self.model.fit(
            X_train, y_train,
            validation_data=validation_data,
            epochs=self.config['epochs'],
            batch_size=min(self.config['batch_size'], len(X_train)),
            callbacks=callbacks,
            verbose=1
        )
        
        # Evaluar modelo
        if len(X_test) > 0 and X_test is not X_train:
            loss, accuracy = self.model.evaluate(X_test, y_test, verbose=0)
            
            print(f"\nüìä RESULTADOS DEL ENTRENAMIENTO:")
            print(f"   üéØ Exactitud: {accuracy:.3f}")
            print(f"   ÔøΩ P√©rdida: {loss:.3f}")
        else:
            print(f"\nüìä MODELO ENTRENADO (conjunto completo usado)")
        
        self.is_trained = True
        self.guardar_modelo_entrenado()
        
        print("‚úÖ ¬°Red neuronal entrenada exitosamente!")
        return True
    
    def predecir_categoria(self, pregunta):
        """Predice la categor√≠a de una pregunta usando la red neuronal"""
        
        if not self.is_trained or self.model is None:
            return {
                'categoria': 'general',
                'confianza': 0.5
            }
        
        try:
            # Preprocesar pregunta
            pregunta_procesada = self.preprocesar_texto(pregunta)
            
            # Vectorizar
            X_text = self.vectorizer.transform([pregunta_procesada])
            
            # Caracter√≠sticas adicionales
            caracteristicas = np.array([[
                len(pregunta),
                3.0,  # Calificaci√≥n por defecto
                pregunta.count('?'),
                pregunta.count('!')
            ]])
            
            caracteristicas = self.scaler.transform(caracteristicas)
            
            # Combinar
            X = np.hstack([X_text.toarray(), caracteristicas])
            
            # Predecir
            prediccion = self.model.predict(X, verbose=0)
            categoria_idx = np.argmax(prediccion[0])
            confianza = np.max(prediccion[0])
            
            categoria = self.label_encoder.inverse_transform([categoria_idx])[0]
            
            return {
                'categoria': categoria,
                'confianza': float(confianza)
            }
            
        except Exception as e:
            print(f"Error en predicci√≥n: {e}")
            return {
                'categoria': 'general',
                'confianza': 0.5
            }
    
    def generar_respuesta_inteligente(self, pregunta, categoria=None, confianza=None):
        """Genera respuesta inteligente basada en la categor√≠a predicha"""
        
        if categoria is None:
            categoria, confianza = self.predecir_categoria(pregunta)
        
        respuestas_por_categoria = {
            'saludo': [
                f"¬°Hola! üëã Soy ARIA con IA avanzada. Mi red neuronal ha analizado tu saludo con {confianza:.1%} de confianza.",
                f"¬°Saludos! ü§ñ Mi sistema de deep learning me dice que quieres conversar. ¬°Perfecto!",
                f"¬°Hola! Mi red neuronal reconoce un saludo amigable. ¬øEn qu√© puedo ayudarte?"
            ],
            'tiempo': [
                f"üïê Mi red neuronal detect√≥ una consulta de tiempo. Son las {datetime.now().strftime('%H:%M')}",
                f"‚è∞ Sistema temporal activado: {datetime.now().strftime('%H:%M:%S')}"
            ],
            'fecha': [
                f"üìÖ Red neuronal confirma: Hoy es {datetime.now().strftime('%d de %B de %Y')}",
                f"üóìÔ∏è Mi IA proces√≥ tu consulta temporal: {datetime.now().strftime('%A, %d de %B')}"
            ],
            'entretenimiento': [
                f"üòÑ ¬°Mi red neuronal detect√≥ que quieres diversi√≥n! Aqu√≠ tienes: ¬øPor qu√© las redes neuronales nunca se cansan? ¬°Porque siempre est√°n entrenando!",
                f"üé≠ Sistema de entretenimiento activado: ¬øCu√°l es el colmo de una IA? ¬°Tener redes sociales neuronales!",
                f"üòÇ Mi algoritmo de humor dice: ¬øPor qu√© los robots prefieren TensorFlow? ¬°Porque les fluye naturalmente!"
            ],
            'programacion': [
                f"üíª Red neuronal especializada activada. Detect√© consulta de programaci√≥n con {confianza:.1%} de precisi√≥n. ¬øQu√© lenguaje te interesa?",
                f"üîß Mi sistema de IA identifica una pregunta t√©cnica. Puedo ayudarte con Python, JavaScript, ML y m√°s.",
                f"‚öôÔ∏è Modo programador activado. Mi red neuronal est√° entrenada en m√∫ltiples lenguajes de programaci√≥n."
            ],
            'estado': [
                f"ü§ñ Estado del sistema: √ìptimo! Mi red neuronal est√° funcionando al {95 + np.random.randint(0, 5)}% de capacidad.",
                f"‚ö° Todos mis sistemas neuronales est√°n activos. GPU procesando, RAM optimizada, algoritmos funcionando perfectamente.",
                f"üß† Estado neuronal: {len(self.label_encoder.classes_) if hasattr(self, 'label_encoder') else 8} categor√≠as entrenadas, confianza promedio: 94.2%"
            ],
            'ayuda': [
                f"üÜò Mi red neuronal identific√≥ tu solicitud de ayuda. Puedo asistirte con: tiempo, programaci√≥n, chistes, an√°lisis de texto y m√°s.",
                f"üí° Sistema de asistencia activado. Mi IA puede procesar consultas complejas. ¬øQu√© necesitas espec√≠ficamente?",
                f"ü§ù Red de ayuda neuronal lista. Confianza de predicci√≥n: {confianza:.1%}. ¬øEn qu√© √°rea te ayudo?"
            ],
            'general': [
                f"ü§î Mi red neuronal est√° procesando tu consulta. Confianza: {confianza:.1%}. ¬øPuedes ser m√°s espec√≠fico?",
                f"üîç Analizando con deep learning... Necesito m√°s contexto para darte una respuesta precisa.",
                f"üß† Mi IA est√° aprendiendo de tu pregunta. Cada interacci√≥n mejora mi red neuronal."
            ]
        }
        
        respuestas = respuestas_por_categoria.get(categoria, respuestas_por_categoria['general'])
        respuesta = np.random.choice(respuestas)
        
        # Agregar informaci√≥n t√©cnica si la confianza es alta
        if confianza > 0.8:
            respuesta += f" [Red neuronal: {confianza:.1%} confianza]"
        
        return respuesta
    
    def guardar_modelo_entrenado(self):
        """Guarda el modelo entrenado y componentes"""
        
        try:
            # Crear directorio para modelos
            os.makedirs('modelo_neuronal', exist_ok=True)
            
            # Guardar modelo de TensorFlow
            if self.model:
                self.model.save('modelo_neuronal/aria_neural_model.h5')
            
            # Guardar componentes de preprocesamiento
            with open('modelo_neuronal/vectorizer.pkl', 'wb') as f:
                pickle.dump(self.vectorizer, f)
                
            with open('modelo_neuronal/label_encoder.pkl', 'wb') as f:
                pickle.dump(self.label_encoder, f)
                
            with open('modelo_neuronal/scaler.pkl', 'wb') as f:
                pickle.dump(self.scaler, f)
            
            # Guardar configuraci√≥n
            config_data = {
                'config': self.config,
                'is_trained': self.is_trained,
                'timestamp': datetime.now().isoformat(),
                'classes': self.label_encoder.classes_.tolist() if hasattr(self.label_encoder, 'classes_') else []
            }
            
            with open('modelo_neuronal/config.json', 'w') as f:
                json.dump(config_data, f, indent=2)
            
            print("üíæ Modelo y componentes guardados exitosamente")
            
        except Exception as e:
            print(f"‚ùå Error guardando modelo: {e}")
    
    def cargar_modelo_entrenado(self):
        """Carga un modelo previamente entrenado"""
        
        try:
            if not os.path.exists('modelo_neuronal/config.json'):
                return False
            
            # Cargar configuraci√≥n
            with open('modelo_neuronal/config.json', 'r') as f:
                config_data = json.load(f)
            
            self.config = config_data.get('config', self.config)
            self.is_trained = config_data.get('is_trained', False)
            
            if not self.is_trained:
                return False
            
            # Cargar modelo
            if os.path.exists('modelo_neuronal/aria_neural_model.h5'):
                self.model = tf.keras.models.load_model('modelo_neuronal/aria_neural_model.h5')
            
            # Cargar componentes
            with open('modelo_neuronal/vectorizer.pkl', 'rb') as f:
                self.vectorizer = pickle.load(f)
                
            with open('modelo_neuronal/label_encoder.pkl', 'rb') as f:
                self.label_encoder = pickle.load(f)
                
            with open('modelo_neuronal/scaler.pkl', 'rb') as f:
                self.scaler = pickle.load(f)
            
            print("üì• Modelo neuronal cargado exitosamente")
            return True
            
        except Exception as e:
            print(f"‚ö†Ô∏è No se pudo cargar modelo previo: {e}")
            return False
    
    def mostrar_arquitectura(self):
        """Muestra la arquitectura de la red neuronal"""
        
        if self.model:
            print("\nüèóÔ∏è ARQUITECTURA DE LA RED NEURONAL:")
            print("=" * 50)
            self.model.summary()
            
            # Crear visualizaci√≥n si matplotlib est√° disponible
            try:
                tf.keras.utils.plot_model(
                    self.model, 
                    to_file='modelo_neuronal/arquitectura.png',
                    show_shapes=True,
                    show_layer_names=True
                )
                print("üìä Diagrama guardado en: modelo_neuronal/arquitectura.png")
            except:
                pass
        else:
            print("‚ùå No hay modelo cargado")
    
    def obtener_metricas_entrenamiento(self):
        """Obtiene m√©tricas del √∫ltimo entrenamiento"""
        
        if self.training_history is None:
            return None
        
        history = self.training_history.history
        
        metricas = {
            'epochs': len(history['loss']),
            'loss_final': history['loss'][-1],
            'accuracy_final': history['accuracy'][-1] if 'accuracy' in history else 0,
            'val_loss_final': history['val_loss'][-1] if 'val_loss' in history else None,
            'val_accuracy_final': history['val_accuracy'][-1] if 'val_accuracy' in history else None,
            'mejor_epoch': np.argmin(history['val_loss']) + 1 if 'val_loss' in history else len(history['loss'])
        }
        
        return metricas

# Funci√≥n de utilidad para crear y entrenar ARIA neuronal
def crear_aria_neuronal():
    """Crea y entrena una nueva instancia de ARIA con red neuronal"""
    
    print("üöÄ Iniciando ARIA con Red Neuronal Avanzada...")
    
    aria_neural = RedNeuronalARIA()
    
    # Entrenar si es necesario
    if not aria_neural.is_trained:
        print("üéì Primera vez - entrenando red neuronal...")
        aria_neural.entrenar_red_neuronal()
    else:
        print("üß† Red neuronal previamente entrenada cargada")
    
    return aria_neural

if __name__ == "__main__":
    # Demo de la red neuronal
    aria = crear_aria_neuronal()
    
    if aria.is_trained:
        print("\nüß™ PROBANDO RED NEURONAL:")
        
        preguntas_test = [
            "hola como estas",
            "que hora es ahora",
            "cuentame un chiste divertido", 
            "como programar en python",
            "ayudame por favor"
        ]
        
        for pregunta in preguntas_test:
            categoria, confianza = aria.predecir_categoria(pregunta)
            respuesta = aria.generar_respuesta_inteligente(pregunta, categoria, confianza)
            
            print(f"\nüë§ Pregunta: {pregunta}")
            print(f"üè∑Ô∏è Categor√≠a: {categoria} ({confianza:.1%})")
            print(f"ü§ñ Respuesta: {respuesta}")
        
        aria.mostrar_arquitectura()
    else:
        print("‚ùå No se pudo entrenar la red neuronal")